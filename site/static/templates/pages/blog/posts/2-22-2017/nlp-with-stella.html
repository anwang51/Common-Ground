<blog-post category="vm.currentPost.category" date="vm.currentPost.date"  name="vm.currentPost.title"  author="vm.currentPost.author"  tags="vm.currentPost.tags" date-path="vm.currentPost.datePath" title-path="vm.currentPost.titlePath">
    <p>Last Saturday, the Luna team dove into the Stella Demo to implement <strong>Natural Language Processing</strong>. If you checked our original source code, you would have seen an ugly jumble of <code>if statements</code> with hard coded mappings between commands and our API functions. To tackle this problem, we split into 2 teams to test which combinations of NLP techniques we learned at Wednesday's Tech Tutorial would allow Stella to understand and support commands that our developers might not anticipate.</p>
    <p><strong>Annie Wang, Arsh Zahed, and Evan Limanto</strong> started off by testing strategies using <strong>Levenshtein Distances</strong> and a <strong>Naive Bayes Classifier</strong>. The idea for Levenshtein Distance was to tokenize and stem each new command and then use edit distance to calculate the difference between the new command and a prepared string template for each known function. The shortest distance would imply that the best function would be the one corresponding to the best-matched template, so Stella would execute that function.</p>
    <img class="blog-post-image" ng-src="templates/pages/blog/posts/{{vm.currentPost.datePath}}/arsh_evan_annie.jpg" alt="Annie Arsh and Evan"/>
    <p>For the Naive Bayes Classifier, the implementation was simply to throw as many possible commands into the classifier as possible in order for it to improve its accuracy on new commands and test data. The problem was creating a sufficient data set for our model. However, we hypothesized that, because Stella has a limited set of possible commands, its need for generalization is smaller, thus, the size of the corpus would only marginally affect the accuracy of the classification (i.e. There are only so many ways to say anything that implies <code>"Stella open help menu"</code>.</p>
    <p>Eventually the group decided that the Naive Bayes model was the best option and is currently improving the strategy by generating weights for each word in a command. This would allow the classifier to be properly biased towards commonly used phrases. In the future, UX testing might be able to generate data sets that we can run <strong>TF-IDF</strong> on to generate these weights more accurately.</p>
    <img class="blog-post-image" src="templates/pages/blog/posts/{{vm.currentPost.datePath}}/mf_hank.jpg" alt="Michael and Hank"/>
    <p>The other team, consisting of <strong>Hank O'Brien, Michael Fan, and Nate Young</strong>, used a phonetic approach. They pre-determined keywords associated with specific commands and matched the phonetic representation of new commands to the phonetic representation of the keywords. This method allows words with ambiguous pronunciations to still map to the correct functions even when the words generated by the <code>webkitSpeechRecognition</code> API are syntactically incorrect.</p>
    <p>This was an extremely fun and exciting Hack Night and we will continue to build a robust NLP foundation for Stella so we can release her on the Chrome Extension Store soon. Natural Language Processing will soon allow her to understand commands that are either incorrectly interpreted by the speech recognizer or are ones she has never even heard before. We are excited about the progress being made and can't wait to transition into building even more robust speech recognition software from scratch using <code>Kaldi</code>, which <strong>Professor Janin</strong> will be coming in to teach next week!</p>
</blog-post>