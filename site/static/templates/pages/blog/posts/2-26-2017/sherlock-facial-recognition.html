<blog-post category="vm.currentPost.category" date="vm.currentPost.date"  name="vm.currentPost.title"  author="vm.currentPost.author"  tags="vm.currentPost.tags" date-path="vm.currentPost.datePath" title-path="vm.currentPost.titlePath">
    <p>From drones to self-driving cars, computer vision is a research field that has been highly developed in the last decade in both the industry and acadmia. In 2005, a Stanford team built a self-driving car named "Stanley", whose software was developed in OpenCV, that won <a href="http://isl.ecst.csuchico.edu/DOCS/darpa2005/DARPA%202005%20Stanley.pdf" target="_blank">Darpa's Grand Challenge</a> for $2,000,000. Companies are currently using computer vision to develop products in augmented reality and mobile applications such as Facebook Messenger and Microsoft Hololens. Recently, an augmented reality unicorn named Magic Leap uses OpenCV directly for its devices. There are many research labs and companies that use computer vision, and you will encounter OpenCV at least once if you pursue research in computer vision.</p>
    <img class="blog-post-image" ng-src="templates/pages/blog/posts/{{vm.currentPost.datePath}}/face-detection.jpg"/>
    <p>In this tutorial, we'll go over a complete tutorial on how to write a basic python script using <strong>OpenCV</strong> in less than 20 lines of code that tracks your face in real-time from your webcam. Now, you're going to need <strong>Python 3.5+</strong> and <strong>OpenCV 3.2</strong>. You'll most likely come across problems that are specific to your computer. However, most bugs can be solved through searching Stack Overflow and other forums. To learn more about OpenCV, the tutorials and documentation for both C++ and Python can be found on the <a href="http://docs.opencv.org/master/" target="_blank">official website</a>.</p>
    <p>After installing the latest version of Python and OpenCV, you should create a python script titled <code>faceDetection.py</code>. We'll be using OpenCV to handle the IO from the webcam using this template.</p>
    <pre><code style="display:block;white-space:pre-wrap">import cv2
camera = cv2.VideoCapture(0)
while True:
	_, frame = camera.read()
	frame = cv2.flip(frame, 1)
	cv2.imshow("Output", frame)
	key = cv2.waitKey(60) & 0xff
	if key == 27:
		break
camera.release()
cv2.destroyAllWindows()</code></pre>
	<p>Now, we'll take a look at the major parts of the template. After importing OpenCV with <code>import cv2</code>, we must create a camera instance with <code>cv2.VideoCapture(0)</code>, which requires either the path to a video file on your computer or zero for the webcam. Then, we can loop through video by reading a frame from the camera instance with <code>camera.read()</code> and flip the frame so that the image becomes a reflection. We can then display the frame using <code>cv2.imshow("Output", frame)</code>, which creates or updates a window. The specify the frame rate, the loop then pauses for 60ms to listen to user input and breaks if the value of the key pressed is 27 or <code>ESC</code>.</p>
	<p>There are many advanced methods for object and face detection including feature matching algorithms such as SIFT, SURF, and ORB. However, we'll be using Haar Cascade Classifiers, which is an object detection method that relies on <a href="http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html" target="_blank">Viola-Jones algorithm</a> implemented in many computer vision frameworks including OpenCV.</p>
	<p>Before creating a cascade classifier instance, you'll need to import a cascade classifier that's been trained for face detection, which can be found <a href="https://raw.githubusercontent.com/callaunchpad/sherlock/master/sherlock/data/haarcascade_frontalface_default.xml" target="_blank">here</a>. Once you download the xml classifier and move it to the same directory as the script, we can import the classifier.</p>
	<pre><code style="display:block;white-space:pre-wrap">import cv2

classifier_path = './haarcascade_frontalface_default.xml'
classifier = cv2.CascadeClassifier(classifier_path)

camera = cv2.VideoCapture(0)
while True:
	_, frame = camera.read()
	frame = cv2.flip(frame, 1)
	cv2.imshow('Output', frame)
	key = cv2.waitKey(60) & 0xff
	if key == 27:
		break
camera.release()
cv2.destroyAllWindows()</code></pre>
	<p>After importing the classifier and converting the frame to grayscale, we can search the frame for matching regions and specify the parameters for the search. To adjust the search, you can modify the <code>scaleFactor</code> and <code>minNeighbors</code>, which adjusts the accuracy and sensitivity respectively. Lastly, we can draw the regions of interest returned by the search, which is a list of rectangles.</p>
	<pre><code style="display:block;white-space:pre-wrap">import cv2

classifier_path = './haarcascade_frontalface_default.xml'
classifier = cv2.CascadeClassifier(classifier_path)

camera = cv2.VideoCapture(0)
while True:
	_, frame = camera.read()
	frame = cv2.flip(frame, 1)
	gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

	regions = classifier.detectMultiScale(
		gray_frame,
		scaleFactor = 1.1,
		minNeighbors = 2
	)

	color_green = (0, 255, 0)
	line_weight = 3
	for (x, y, w, h) in regions:
		cv2.rectangle(frame,
			(x, y),
			(x + w, y + h), 
			color_green, 
			line_weight
		)

	cv2.imshow('Output', frame)
	key = cv2.waitKey(60) & 0xff
	if key == 27:
		break

camera.release()
cv2.destroyAllWindows()</code></pre>
	<p>Now, you have a face detector in 20 lines of code! There are many resources online if you're interested in learning more about the algorithms behind the methods. However, hopefully this tutorial has showcased the power of OpenCV and its potential applications.</p>
	<img class="blog-post-image" ng-src="templates/pages/blog/posts/{{vm.currentPost.datePath}}/vishal_darren_harika_peter.jpg"/>
	<p><strong>About Team Sherlock</strong></p>
	<p>We've been very fortunate this semester to have talented team of students working on Project Sherlock, a cloud API that provides optimized algorithms for real-time computer vision algorithms. Currently, our hand tracking team includes <strong>Vishal Satish, Darren Lee, George Zhang, Harika Kalidhindi</strong> who are working on estimating hand models and extracting features. Our face detection team includes <strong>Caleb Siu, Nicolas Zoghb, Nipun Ramakrishnan, Nina Chang</strong> who are working to develop fast Haar Cascades using local search.</p>
</blog-post>
