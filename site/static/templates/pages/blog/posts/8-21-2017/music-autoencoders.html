<blog-post category="vm.currentPost.category" date="vm.currentPost.date"  name="vm.currentPost.title"  author="vm.currentPost.author"  tags="vm.currentPost.tags" date-path="vm.currentPost.datePath" title-path="vm.currentPost.titlePath">
    <p>As people, one of our key traits is our ability to create. We create tools and inventions, we create art and music, and most importantly, we create thoughts. Our understanding of our suroundings and circumstances are directly reflected in our ability to "create". This is why it is so important to make machine learning models that create as well.</p>

    <p>Recently, Google Brain released <a href="https://magenta.tensorflow.org/">Magenta</a> to the public, their project to write and create music using generative neural networks. A couple months ago, the team added <a href="https://magenta.tensorflow.org/performance-rnn">Performance-RNN</a> to Magenta, a model trained on approximately 1,400 piano performances by professional pianists. The power of this specific model is its ability to simulate expressive timing and dynamics, features that were not found in previous models such as BachBot. Needless to say, this model isn't foolproof yet, but it is still very powerful.</p>

    <p>First we provide a primer to the model. This serves as "inspiration" for the model to extend off of. Here is the primer I used.</p>
    <iframe width="100%" height="200" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/338929532&amp;color=ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;visual=true"></iframe>

    <p>This second upload is the original output from Performance-RNN based off of the primer piece. It's important to note that the model's output gets more and more chaotic as time passes on. This has to do with the nature of LSTMs and compounding errors. Nonetheless, the model is in scale with the primer piece for nearly all of the composition.</p>
    <iframe width="100%" height="200" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/338796907&amp;color=ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;visual=true"></iframe>
    <p>This last Soundloud upload is an example of a composition almost entirely built on a generation by Performance-RNN, showing how a composer might be able to use models like Performance-RNN to help write songs.</p>

    <iframe width="100%" height="200" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/338778404&amp;color=ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;visual=true"></iframe>
    <p>The key to these generations and the rest of Magenta is the use of <b>autoencoders</b>, a special neural network architecture. In this tutorial, we will explore the fundamental concepts and implement some code to get a basic auto-encoder up an running.</p>

    <p>An autoencoder is a neural network that is trained to output exactly what was input. However, what's important about autoencoders is before generating the output, they must first compress the input data into a <b>feature vector</b> of a lower dimensionality than the input and output vectors. This means the neural network has two parts, an <b>encoder</b>, which attempts to effectively compress the input into the feature vector, and the <b>decoder</b>, which attempts to reconstruct the original input from the feature vector.</p>
    <img class="blog-post-image" ng-src="templates/pages/blog/posts/{{vm.currentPost.datePath}}/autoencoder.png"/>

    <p>In the case of Performance-RNN, the primer piece was encoded into a corresponding feature vector. The decoder then did its best job in decoding the feature vector based off of the pieces it's seen before (which are professional performances, not a lullaby tune like the primer), but clearly does a far from perfect job at duplicating the input piece. However, our goal is to create something new, not replicate an input, so the noise and "imperfections" of the decoder are actually what we are looking for. This gives us a new piece that is inspired by the primer.</p>

    <p>For this tutorial, we will create a regular autoencoder to recreate images from the classic MNIST dataset using TensorFlow. </p>

    <p>Firt thing first, let's import all the libraries we'll need.</p>
    <pre><code style="display:block;white-space:pre-wrap">import numpy as np
import tensorflow as tf

import matplotlib.pyplot as plt

#Training Data
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("MNIST_data", one_hot=True)   	
    </code></pre>
    <p>Now let's set up the parameters and layers. We'll keep this model relatively small for the sake of simplicity, so we'll go with two hidden layers each for the encoder and decoder. Feel free to mess with some of these parameters. The image sizes of the MNIST samples are 28x28, so we'll need an input vector of 784 dimensions.</p>
    <pre><code style="display:block;white-space:pre-wrap">#Parameters
learning_rate = 0.01
num_epochs = 20
batch_size = 256
display_step = 1
examples_to_show = 10

#Network Parameters
n_hidden_1 = 256
n_hidden_2 = 128
n_input = 784

#Visible Layer
X = tf.placeholder("float", [None, n_input])

"""
Note how the hidden layers of the encoder and decorder are "mirrored".
"""
weights = {
    'e_1' : tf.Variable(tf.random_normal([n_input, n_hidden_1])),
	'e_2' : tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),
	'd_1' : tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),
	'd_2' : tf.Variable(tf.random_normal([n_hidden_1, n_input]))
}

biases = {
	'e_1' : tf.Variable(tf.random_normal([n_hidden_1])),
	'e_2' : tf.Variable(tf.random_normal([n_hidden_2])),
	'd_1' : tf.Variable(tf.random_normal([n_hidden_1])),
	'd_2' : tf.Variable(tf.random_normal([n_input]))
}</code></pre>

	<p>Now that our parameters and variables are set up, we can make the encoder and decoder. For our activation functions, we will opt for the sigmoid function. While ReLU is probably more used than sigmoid in most modern architectures, ReLU is not suited for this autoencoder because of it's lack of an upperbound and its vanishing gradient.</p>
	<p>Additionally we'll be using Minimum Mean Square Error for our cost.</p>
	<pre><code style="display:block;white-space:pre-wrap">def encoder(x):
	# Encoder Hidden layer with sigmoid activation #1
    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['e_1']),
                                   biases['e_1']))
    # Encoder Hidden layer with sigmoid activation #2
    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['e_2']),
                                   biases['e_2']))
    return layer_2

def decoder(x):
	# Decoder Hidden layer with sigmoid activation #1
    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['d_1']),
                                   biases['d_1']))
    # Decoder Hidden layer with sigmoid activation #2
    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['d_2']),
                                   biases['d_2']))
    return layer_2

    #Construct model
encoder_op = encoder(X)
decoder_op = decoder(encoder_op)

#Prediction
y_pred = decoder_op

#Targets (Labels) are the input data
y_true = X

#Define loss and optimizer, minimal square error
cost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))
optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)

# Initializing the variables
init = tf.global_variables_initializer()
</code></pre>
	<p>With that, the model is entirely built. All we need to do now is run it. We can do this just like any other model in TensorFlow.</p>
	<pre><code style="display:block;white-space:pre-wrap">#Launch the graph
with tf.Session() as sess:
    sess.run(init)	
    total_batch = int(mnist.train.num_examples/batch_size)

    #Train
    for epoch in range(num_epochs):
        #Loop over batches
        for i in range(total_batch):
            batch_xs, batch_ys = mnist.train.next_batch(batch_size)
            # Run optimization op (backprop) and cost op (to get loss value)
            _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})
        # Display logs per epoch step
            if epoch % display_step == 0:
                print("Epoch:", '%04d' % (epoch+1),
                "cost=", "{:.9f}".format(c))
    print("Optimization Finished!")

    #Applying encode and decode over test set
    encode_decode = sess.run(
        y_pred, feed_dict={X: mnist.test.images[:examples_to_show]})
    # Compare original images with their reconstructions
    f, a = plt.subplots(2, 10, figsize=(10, 2))
    for i in range(examples_to_show):
        a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))
        a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))
    plt.show()
    plt.draw()
	</code></pre>

	<p>That's all the code there is! You can check out the code from this <a href="https://github.com/callaunchpad/Autoencoder-Tutorial" target="_blank">github repo</a>. After just 20 epochs of training (taking me about a minute to train on my Macbook), I got a bit over 90% accuracy. Here is a sample of the results.</p>
	<img class="blog-post-image" ng-src="templates/pages/blog/posts/{{vm.currentPost.datePath}}/autoencoder_result1.png"/>
	<p>There is some clear noise and mistakes in the results, but for a weak model and just a few lines of code, it fares pretty well.</p> 
    <p>This model can then be extended to generate samples. Such an architecture is called a <b>Variational Autoencoder (VAE)</b>. We can't just generate of off random feature vectors, so instead what we do is we make the loss function for the encoder follow a unit multivariate gaussian and sample from that gaussian.</p>
   <p>If you're interested in learning more about machine learning, neural networks, and autoencoders, follow us on Facebook, check out other blog posts, and join us by submitting your application <a href="http://callaunchpad.org/#/apply" target="_blank">here</a>.</p>
</blog-post>
